{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# EfficientNet (pip install efficientnet-pytorch)\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "# ==========================\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "# ==========================\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==============================\n",
    "# ✅ Early Stopping 클래스\n",
    "# ==============================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ==============================\n",
    "# ✅ Residual Block 정의\n",
    "# ==============================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ==============================\n",
    "# ✅ ASPP Block 정의\n",
    "# ==============================\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ==============================\n",
    "# ✅ EfficientNet + VGG + Residual + ASPP 모델 정의\n",
    "# ==============================\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  # Residual Block 추가\n",
    "\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "\n",
    "        fused_features = self.res_block(fused_features)  # Residual Block 적용\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        return self.classifier(aspp_features)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.3049 | Train Acc: 0.1540 | Val Loss: 9.5322 | Val Acc: 0.1808\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0264 | Train Acc: 0.2274 | Val Loss: 1.7281 | Val Acc: 0.2768\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8039 | Train Acc: 0.2401 | Val Loss: 1.7300 | Val Acc: 0.2147\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7511 | Train Acc: 0.2740 | Val Loss: 1.6680 | Val Acc: 0.2203\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6344 | Train Acc: 0.3150 | Val Loss: 1.5305 | Val Acc: 0.4350\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5053 | Train Acc: 0.4393 | Val Loss: 1.3178 | Val Acc: 0.5311\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3169 | Train Acc: 0.5297 | Val Loss: 1.6638 | Val Acc: 0.4802\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2884 | Train Acc: 0.6073 | Val Loss: 1.1122 | Val Acc: 0.7514\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1596 | Train Acc: 0.6497 | Val Loss: 1.2163 | Val Acc: 0.6554\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0096 | Train Acc: 0.7684 | Val Loss: 0.9274 | Val Acc: 0.8079\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9583 | Train Acc: 0.7768 | Val Loss: 1.0582 | Val Acc: 0.7458\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8917 | Train Acc: 0.8291 | Val Loss: 1.0030 | Val Acc: 0.8305\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7687 | Train Acc: 0.8898 | Val Loss: 0.9051 | Val Acc: 0.8531\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6703 | Train Acc: 0.9379 | Val Loss: 0.8321 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6501 | Train Acc: 0.9435 | Val Loss: 0.8035 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6257 | Train Acc: 0.9562 | Val Loss: 0.8278 | Val Acc: 0.8588\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7484 | Train Acc: 0.9181 | Val Loss: 0.9147 | Val Acc: 0.7966\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7556 | Train Acc: 0.9153 | Val Loss: 0.8714 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6570 | Train Acc: 0.9562 | Val Loss: 0.8631 | Val Acc: 0.8644\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6258 | Train Acc: 0.9605 | Val Loss: 0.8533 | Val Acc: 0.8701\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5835 | Train Acc: 0.9760 | Val Loss: 0.9326 | Val Acc: 0.7966\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5823 | Train Acc: 0.9760 | Val Loss: 0.8043 | Val Acc: 0.8983\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6068 | Train Acc: 0.9703 | Val Loss: 0.8458 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5818 | Train Acc: 0.9718 | Val Loss: 0.8271 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5706 | Train Acc: 0.9816 | Val Loss: 0.9914 | Val Acc: 0.7627\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # ✅ EfficientNet의 일부 블록만 Unfreeze (초기 블록 2개만 학습)\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name:  # 블록 0, 1만 학습\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        return self.classifier(aspp_features)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.2672 | Train Acc: 0.1667 | Val Loss: 3.3439 | Val Acc: 0.2994\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8356 | Train Acc: 0.2542 | Val Loss: 1.6732 | Val Acc: 0.3842\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6044 | Train Acc: 0.3842 | Val Loss: 1.4448 | Val Acc: 0.5593\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3220 | Train Acc: 0.5636 | Val Loss: 1.1580 | Val Acc: 0.6893\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0856 | Train Acc: 0.7133 | Val Loss: 1.1997 | Val Acc: 0.6836\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9811 | Train Acc: 0.7684 | Val Loss: 1.0257 | Val Acc: 0.7627\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8592 | Train Acc: 0.8390 | Val Loss: 0.8799 | Val Acc: 0.8418\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8329 | Train Acc: 0.8446 | Val Loss: 0.9844 | Val Acc: 0.7910\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7066 | Train Acc: 0.9181 | Val Loss: 1.1848 | Val Acc: 0.6893\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7207 | Train Acc: 0.9054 | Val Loss: 0.8581 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6787 | Train Acc: 0.9237 | Val Loss: 0.8425 | Val Acc: 0.8475\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6098 | Train Acc: 0.9576 | Val Loss: 0.8192 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5768 | Train Acc: 0.9774 | Val Loss: 0.8450 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5770 | Train Acc: 0.9647 | Val Loss: 0.7575 | Val Acc: 0.8757\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5594 | Train Acc: 0.9746 | Val Loss: 0.7617 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5259 | Train Acc: 0.9859 | Val Loss: 0.9226 | Val Acc: 0.7966\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5607 | Train Acc: 0.9831 | Val Loss: 0.8292 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5808 | Train Acc: 0.9746 | Val Loss: 0.9217 | Val Acc: 0.7853\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5325 | Train Acc: 0.9845 | Val Loss: 0.8968 | Val Acc: 0.8079\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5567 | Train Acc: 0.9703 | Val Loss: 0.8127 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5353 | Train Acc: 0.9774 | Val Loss: 0.7634 | Val Acc: 0.8870\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5300 | Train Acc: 0.9816 | Val Loss: 0.7547 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5548 | Train Acc: 0.9845 | Val Loss: 0.7666 | Val Acc: 0.8927\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4991 | Train Acc: 0.9901 | Val Loss: 0.7813 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4978 | Train Acc: 0.9944 | Val Loss: 0.7665 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5103 | Train Acc: 0.9915 | Val Loss: 0.7700 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5023 | Train Acc: 0.9915 | Val Loss: 0.8320 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5116 | Train Acc: 0.9915 | Val Loss: 0.8478 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5063 | Train Acc: 0.9915 | Val Loss: 0.8160 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5027 | Train Acc: 0.9887 | Val Loss: 0.8381 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5101 | Train Acc: 0.9873 | Val Loss: 0.7589 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4992 | Train Acc: 0.9958 | Val Loss: 0.7722 | Val Acc: 0.8927\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # ✅ EfficientNet의 일부 블록만 Unfreeze (초기 블록 2개만 학습)\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name:  # 블록 0, 1만 학습\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        return self.classifier(aspp_features)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.5274 | Train Acc: 0.2797 | Val Loss: 10.5117 | Val Acc: 0.2260\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4507 | Train Acc: 0.4718 | Val Loss: 1.6894 | Val Acc: 0.4350\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0423 | Train Acc: 0.7189 | Val Loss: 1.2445 | Val Acc: 0.6667\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8509 | Train Acc: 0.8065 | Val Loss: 0.8584 | Val Acc: 0.8192\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6888 | Train Acc: 0.9167 | Val Loss: 1.3174 | Val Acc: 0.6667\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6356 | Train Acc: 0.9322 | Val Loss: 1.0596 | Val Acc: 0.7514\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5970 | Train Acc: 0.9463 | Val Loss: 0.8313 | Val Acc: 0.8475\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5356 | Train Acc: 0.9703 | Val Loss: 0.9633 | Val Acc: 0.8023\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5701 | Train Acc: 0.9703 | Val Loss: 0.7923 | Val Acc: 0.8588\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5224 | Train Acc: 0.9831 | Val Loss: 0.8750 | Val Acc: 0.8249\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5742 | Train Acc: 0.9633 | Val Loss: 0.8246 | Val Acc: 0.8644\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5855 | Train Acc: 0.9619 | Val Loss: 0.8363 | Val Acc: 0.8701\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5730 | Train Acc: 0.9718 | Val Loss: 0.8835 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5421 | Train Acc: 0.9774 | Val Loss: 0.9216 | Val Acc: 0.7966\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5259 | Train Acc: 0.9859 | Val Loss: 0.8868 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5358 | Train Acc: 0.9859 | Val Loss: 0.8460 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4799 | Train Acc: 0.9929 | Val Loss: 0.8116 | Val Acc: 0.8757\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4839 | Train Acc: 0.9915 | Val Loss: 0.7813 | Val Acc: 0.8814\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5452 | Train Acc: 0.9703 | Val Loss: 0.8605 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5049 | Train Acc: 0.9859 | Val Loss: 0.8465 | Val Acc: 0.8192\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4902 | Train Acc: 0.9929 | Val Loss: 0.8021 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4876 | Train Acc: 0.9929 | Val Loss: 0.7565 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4884 | Train Acc: 0.9887 | Val Loss: 0.7858 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5001 | Train Acc: 0.9816 | Val Loss: 0.7621 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4741 | Train Acc: 0.9929 | Val Loss: 0.7386 | Val Acc: 0.8870\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4805 | Train Acc: 0.9915 | Val Loss: 0.8383 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6061 | Train Acc: 0.9520 | Val Loss: 0.8790 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5674 | Train Acc: 0.9619 | Val Loss: 0.8013 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5726 | Train Acc: 0.9732 | Val Loss: 0.7949 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5141 | Train Acc: 0.9859 | Val Loss: 0.8433 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5057 | Train Acc: 0.9901 | Val Loss: 0.8436 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4981 | Train Acc: 0.9887 | Val Loss: 0.7854 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 33/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4982 | Train Acc: 0.9915 | Val Loss: 0.7946 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 34/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4619 | Train Acc: 0.9986 | Val Loss: 0.7675 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 35/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4617 | Train Acc: 0.9986 | Val Loss: 0.7543 | Val Acc: 0.8814\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # GAP 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 256 차원에서 512 차원으로 축소\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "        # ✅ EfficientNet의 일부 블록만 Unfreeze (초기 블록 2개만 학습)\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name:  # 블록 0, 1만 학습\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.5600 | Train Acc: 0.2627 | Val Loss: 1.6581 | Val Acc: 0.3220\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4925 | Train Acc: 0.4364 | Val Loss: 1.2412 | Val Acc: 0.6158\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0990 | Train Acc: 0.6949 | Val Loss: 1.4725 | Val Acc: 0.5932\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8299 | Train Acc: 0.8333 | Val Loss: 0.9517 | Val Acc: 0.7853\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7319 | Train Acc: 0.8912 | Val Loss: 0.9250 | Val Acc: 0.8305\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6113 | Train Acc: 0.9492 | Val Loss: 0.9886 | Val Acc: 0.8023\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6088 | Train Acc: 0.9435 | Val Loss: 0.9173 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5495 | Train Acc: 0.9661 | Val Loss: 0.9084 | Val Acc: 0.8079\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6317 | Train Acc: 0.9407 | Val Loss: 0.9179 | Val Acc: 0.8362\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5708 | Train Acc: 0.9689 | Val Loss: 1.2544 | Val Acc: 0.6610\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6171 | Train Acc: 0.9492 | Val Loss: 0.9717 | Val Acc: 0.8249\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6511 | Train Acc: 0.9421 | Val Loss: 0.8170 | Val Acc: 0.8927\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5864 | Train Acc: 0.9661 | Val Loss: 0.9873 | Val Acc: 0.7514\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5884 | Train Acc: 0.9506 | Val Loss: 0.8205 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5380 | Train Acc: 0.9788 | Val Loss: 0.7546 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5360 | Train Acc: 0.9661 | Val Loss: 0.7596 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4914 | Train Acc: 0.9887 | Val Loss: 0.7036 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5186 | Train Acc: 0.9746 | Val Loss: 0.9211 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5785 | Train Acc: 0.9534 | Val Loss: 0.8877 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6000 | Train Acc: 0.9562 | Val Loss: 0.7614 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5523 | Train Acc: 0.9718 | Val Loss: 0.9356 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5421 | Train Acc: 0.9746 | Val Loss: 0.6999 | Val Acc: 0.9096\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5302 | Train Acc: 0.9661 | Val Loss: 0.7116 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5384 | Train Acc: 0.9774 | Val Loss: 0.8844 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4951 | Train Acc: 0.9859 | Val Loss: 0.7301 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5019 | Train Acc: 0.9831 | Val Loss: 0.7392 | Val Acc: 0.9040\n",
      "\n",
      "[Epoch 27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5136 | Train Acc: 0.9831 | Val Loss: 0.7775 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4939 | Train Acc: 0.9873 | Val Loss: 0.7123 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5078 | Train Acc: 0.9788 | Val Loss: 0.7581 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5205 | Train Acc: 0.9887 | Val Loss: 0.7982 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5028 | Train Acc: 0.9816 | Val Loss: 0.7993 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4940 | Train Acc: 0.9873 | Val Loss: 0.7158 | Val Acc: 0.8927\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    " import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # GAP 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 256 차원에서 512 차원으로 축소\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\IIALAB/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:50<00:00, 11.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7076 | Train Acc: 0.2444 | Val Loss: 1.9248 | Val Acc: 0.2994\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3111 | Train Acc: 0.5946 | Val Loss: 4.3120 | Val Acc: 0.3164\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2383 | Train Acc: 0.6907 | Val Loss: 1.2640 | Val Acc: 0.6780\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8453 | Train Acc: 0.8432 | Val Loss: 0.8443 | Val Acc: 0.8531\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6513 | Train Acc: 0.9336 | Val Loss: 0.8067 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5614 | Train Acc: 0.9718 | Val Loss: 1.0916 | Val Acc: 0.7514\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6315 | Train Acc: 0.9421 | Val Loss: 0.9307 | Val Acc: 0.7853\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6959 | Train Acc: 0.9195 | Val Loss: 0.8741 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6161 | Train Acc: 0.9492 | Val Loss: 0.9364 | Val Acc: 0.7684\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6180 | Train Acc: 0.9506 | Val Loss: 0.9374 | Val Acc: 0.7966\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6259 | Train Acc: 0.9477 | Val Loss: 0.9017 | Val Acc: 0.8136\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5494 | Train Acc: 0.9718 | Val Loss: 0.8432 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5240 | Train Acc: 0.9788 | Val Loss: 0.7609 | Val Acc: 0.8701\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4922 | Train Acc: 0.9887 | Val Loss: 0.7338 | Val Acc: 0.8814\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5035 | Train Acc: 0.9915 | Val Loss: 0.6783 | Val Acc: 0.9040\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5331 | Train Acc: 0.9732 | Val Loss: 0.8560 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5193 | Train Acc: 0.9746 | Val Loss: 0.8898 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5039 | Train Acc: 0.9831 | Val Loss: 0.8145 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4636 | Train Acc: 0.9972 | Val Loss: 0.7854 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4897 | Train Acc: 0.9845 | Val Loss: 0.8478 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5063 | Train Acc: 0.9774 | Val Loss: 0.8876 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5559 | Train Acc: 0.9661 | Val Loss: 0.9375 | Val Acc: 0.7910\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5181 | Train Acc: 0.9774 | Val Loss: 0.8701 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5096 | Train Acc: 0.9845 | Val Loss: 0.7999 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4809 | Train Acc: 0.9944 | Val Loss: 0.7787 | Val Acc: 0.8644\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.9040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    " import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        # ✅ VGG16 → VGG19 변경\n",
    "        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG19의 출력 채널 수\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # GAP 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 256 차원에서 512 차원으로 축소\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9099 | Train Acc: 0.2641 | Val Loss: 2.4677 | Val Acc: 0.3842\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3733 | Train Acc: 0.5706 | Val Loss: 1.2310 | Val Acc: 0.6328\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0689 | Train Acc: 0.6977 | Val Loss: 1.5944 | Val Acc: 0.6441\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8537 | Train Acc: 0.8404 | Val Loss: 1.2747 | Val Acc: 0.6384\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7854 | Train Acc: 0.8743 | Val Loss: 1.0179 | Val Acc: 0.7910\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6712 | Train Acc: 0.9068 | Val Loss: 0.9775 | Val Acc: 0.8079\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7006 | Train Acc: 0.9294 | Val Loss: 0.7845 | Val Acc: 0.8644\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6636 | Train Acc: 0.9266 | Val Loss: 0.7958 | Val Acc: 0.8927\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5553 | Train Acc: 0.9760 | Val Loss: 0.7595 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7054 | Train Acc: 0.9195 | Val Loss: 1.0137 | Val Acc: 0.8192\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6686 | Train Acc: 0.9350 | Val Loss: 0.8745 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5607 | Train Acc: 0.9718 | Val Loss: 0.7617 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6087 | Train Acc: 0.9534 | Val Loss: 0.9596 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5398 | Train Acc: 0.9774 | Val Loss: 0.8819 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5247 | Train Acc: 0.9718 | Val Loss: 0.7839 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5124 | Train Acc: 0.9845 | Val Loss: 0.8392 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5185 | Train Acc: 0.9873 | Val Loss: 0.7866 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4787 | Train Acc: 0.9929 | Val Loss: 0.7732 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4674 | Train Acc: 0.9887 | Val Loss: 0.7638 | Val Acc: 0.8644\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        # ✅ VGG16 → VGG19 변경\n",
    "        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG19의 출력 채널 수\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # GAP 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 256 차원에서 512 차원으로 축소\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "        vgg_features = nn.Dropout(0.3)(vgg_features)\n",
    "\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
