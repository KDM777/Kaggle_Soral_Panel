{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# EfficientNet (pip install efficientnet-pytorch)\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "# ==========================\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "# ==========================\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==============================\n",
    "# ✅ Early Stopping 클래스\n",
    "# ==============================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ==========================\n",
    "# ✅ ASPP Block 정의 (Global Branch 포함)\n",
    "# ==========================\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ==========================\n",
    "# ✅ EfficientNet + VGG + ASPP 모델 정의\n",
    "# ==========================\n",
    "class EfficientNetVGGASPPHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EfficientNetVGGASPPHybrid, self).__init__()\n",
    "\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        output = self.classifier(aspp_features)\n",
    "        return output\n",
    "\n",
    "# ==========================\n",
    "# ✅ 데이터 로딩\n",
    "# ==========================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetVGGASPPHybrid(num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프 (Epochs 포함)\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.5975 | Train Acc: 0.4011 | Val Loss: 2.0866 | Val Acc: 0.3842\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3336 | Train Acc: 0.5975 | Val Loss: 1.7868 | Val Acc: 0.6441\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9707 | Train Acc: 0.7980 | Val Loss: 0.9054 | Val Acc: 0.8362\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8315 | Train Acc: 0.8559 | Val Loss: 1.0358 | Val Acc: 0.7740\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6811 | Train Acc: 0.9251 | Val Loss: 1.0254 | Val Acc: 0.8192\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6587 | Train Acc: 0.9336 | Val Loss: 0.8394 | Val Acc: 0.8644\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5722 | Train Acc: 0.9831 | Val Loss: 0.7490 | Val Acc: 0.8983\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5469 | Train Acc: 0.9802 | Val Loss: 0.8638 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5680 | Train Acc: 0.9703 | Val Loss: 0.7640 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5661 | Train Acc: 0.9831 | Val Loss: 0.8490 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5380 | Train Acc: 0.9831 | Val Loss: 0.7743 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5080 | Train Acc: 0.9986 | Val Loss: 0.8362 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5101 | Train Acc: 0.9929 | Val Loss: 0.7516 | Val Acc: 0.8983\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5171 | Train Acc: 0.9915 | Val Loss: 0.7578 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5097 | Train Acc: 0.9901 | Val Loss: 0.8005 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4961 | Train Acc: 0.9958 | Val Loss: 0.7715 | Val Acc: 0.9040\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4864 | Train Acc: 0.9972 | Val Loss: 0.7894 | Val Acc: 0.9040\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.9040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# EfficientNet (pip install efficientnet-pytorch)\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "# ==========================\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "# ==========================\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==============================\n",
    "# ✅ Early Stopping 클래스\n",
    "# ==============================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ==========================\n",
    "# ✅ ASPP Block 정의 (Global Branch 포함)\n",
    "# ==========================\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ==========================\n",
    "# ✅ EfficientNet + VGG + ASPP 모델 정의\n",
    "# ==========================\n",
    "class EfficientNetVGGASPPHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EfficientNetVGGASPPHybrid, self).__init__()\n",
    "\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  \n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        output = self.classifier(aspp_features)\n",
    "        return output\n",
    "\n",
    "# ==========================\n",
    "# ✅ 데이터 로딩\n",
    "# ==========================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetVGGASPPHybrid(num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프 (Epochs 포함)\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Input] torch.Size([1, 3, 224, 224])\n",
      "EfficientNet output: torch.Size([1, 1280, 7, 7])\n",
      "EfficientNet pooled: torch.Size([1, 1280, 7, 7])\n",
      "EfficientNet 1x1 Conv: torch.Size([1, 1024, 7, 7])\n",
      "VGG16 output: torch.Size([1, 512, 7, 7])\n",
      "VGG16 pooled: torch.Size([1, 512, 7, 7])\n",
      "VGG16 1x1 Conv: torch.Size([1, 1024, 7, 7])\n",
      "Fused features: torch.Size([1, 2048, 7, 7])\n",
      "ASPP output: torch.Size([1, 256, 7, 7])\n",
      "Flattened: torch.Size([1, 12544])\n",
      "[Output] torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # ⭐ global_avg도 256채널로 맞춰주는 Conv\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        # (batch, 2048, 1, 1) → (batch, 256, 1, 1)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        # (batch, 256, 1, 1) → upsample → (batch, 256, 7, 7)\n",
    "        global_avg = nn.functional.interpolate(\n",
    "            global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True\n",
    "        )\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        out = self.conv1x1_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EfficientNetVGGASPPHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=6, print_shapes=True):\n",
    "        super(EfficientNetVGGASPPHybrid, self).__init__()\n",
    "        self.print_shapes = print_shapes  # 디버깅 여부 설정\n",
    "\n",
    "        # ✅ EfficientNet-b0\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        # ✅ VGG16\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # ✅ Feature Map 크기 조정\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG16 마지막 Conv 출력\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        # ✅ 1x1 Conv 적용하여 채널 맞추기\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)  # 1280 → 1024\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)  # 512 → 1024\n",
    "\n",
    "        # ✅ ASPP 블록\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)  # 채널 유지\n",
    "\n",
    "        # ✅ Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.print_shapes:\n",
    "            print(f\"\\n[Input] {x.shape}\")  # ✅ 입력 이미지 크기\n",
    "\n",
    "        # ✅ EfficientNet Feature Extraction\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        if self.print_shapes:\n",
    "            print(f\"EfficientNet output: {eff_features.shape}\")  # 예상: (batch, 1280, 7, 7)\n",
    "\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"EfficientNet pooled: {eff_features.shape}\")  # 예상: (batch, 1280, 7, 7)\n",
    "\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"EfficientNet 1x1 Conv: {eff_features.shape}\")  # 예상: (batch, 1024, 7, 7)\n",
    "\n",
    "        # ✅ VGG16 Feature Extraction\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        if self.print_shapes:\n",
    "            print(f\"VGG16 output: {vgg_features.shape}\")  # 예상: (batch, 512, 7, 7)\n",
    "\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"VGG16 pooled: {vgg_features.shape}\")  # 예상: (batch, 512, 7, 7)\n",
    "\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"VGG16 1x1 Conv: {vgg_features.shape}\")  # 예상: (batch, 1024, 7, 7)\n",
    "\n",
    "        # ✅ Feature Concatenation\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)\n",
    "        if self.print_shapes:\n",
    "            print(f\"Fused features: {fused_features.shape}\")  # 예상: (batch, 2048, 7, 7)\n",
    "\n",
    "        # ✅ ASPP 적용\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"ASPP output: {aspp_features.shape}\")  # 예상: (batch, 256, 7, 7)\n",
    "\n",
    "        # ✅ Flatten 후 Classifier 적용\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        if self.print_shapes:\n",
    "            print(f\"Flattened: {aspp_features.shape}\")  # 예상: (batch, 256*7*7)\n",
    "\n",
    "        output = self.classifier(aspp_features)\n",
    "        if self.print_shapes:\n",
    "            print(f\"[Output] {output.shape}\")  # ✅ 최종 출력 크기 (batch, num_classes)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ 모델 생성 (print_shapes=True 설정)\n",
    "model = EfficientNetVGGASPPHybrid(num_classes=6, print_shapes=True).to(device)\n",
    "\n",
    "# ✅ 더미 입력 데이터 생성 (Batch=1, RGB=3, 224x224)\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# ✅ 모델 실행 (텐서 크기 출력)\n",
    "output = model(dummy_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.7695 | Train Acc: 0.4110 | Val Loss: 2.7277 | Val Acc: 0.4237\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2522 | Train Acc: 0.6610 | Val Loss: 1.3098 | Val Acc: 0.6667\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9038 | Train Acc: 0.7938 | Val Loss: 1.0393 | Val Acc: 0.7797\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7962 | Train Acc: 0.8814 | Val Loss: 1.0518 | Val Acc: 0.7571\n",
      "\n",
      "[Epoch 5/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6855 | Train Acc: 0.9209 | Val Loss: 1.0618 | Val Acc: 0.7684\n",
      "\n",
      "[Epoch 6/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6612 | Train Acc: 0.9379 | Val Loss: 0.8371 | Val Acc: 0.8644\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5999 | Train Acc: 0.9590 | Val Loss: 0.7433 | Val Acc: 0.9096\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 8/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5629 | Train Acc: 0.9732 | Val Loss: 0.8597 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 9/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5685 | Train Acc: 0.9774 | Val Loss: 0.8081 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 10/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5835 | Train Acc: 0.9718 | Val Loss: 0.7690 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 11/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5383 | Train Acc: 0.9915 | Val Loss: 0.7665 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 12/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5204 | Train Acc: 0.9901 | Val Loss: 0.7561 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 13/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4991 | Train Acc: 0.9958 | Val Loss: 0.7762 | Val Acc: 0.9040\n",
      "\n",
      "[Epoch 14/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4919 | Train Acc: 0.9972 | Val Loss: 0.7908 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 15/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4940 | Train Acc: 0.9944 | Val Loss: 0.7541 | Val Acc: 0.8983\n",
      "\n",
      "[Epoch 16/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4785 | Train Acc: 0.9986 | Val Loss: 0.7423 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 17/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4775 | Train Acc: 0.9986 | Val Loss: 0.7313 | Val Acc: 0.8983\n",
      "\n",
      "[Epoch 18/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4697 | Train Acc: 0.9986 | Val Loss: 0.7037 | Val Acc: 0.9096\n",
      "\n",
      "[Epoch 19/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4738 | Train Acc: 0.9972 | Val Loss: 0.7090 | Val Acc: 0.9096\n",
      "\n",
      "[Epoch 20/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4739 | Train Acc: 0.9986 | Val Loss: 0.7222 | Val Acc: 0.9040\n",
      "\n",
      "[Epoch 21/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4718 | Train Acc: 0.9986 | Val Loss: 0.7424 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 22/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4814 | Train Acc: 0.9958 | Val Loss: 0.7240 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 23/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4761 | Train Acc: 0.9929 | Val Loss: 0.7262 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 24/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5224 | Train Acc: 0.9859 | Val Loss: 0.7960 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 25/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5276 | Train Acc: 0.9887 | Val Loss: 0.7821 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 26/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5029 | Train Acc: 0.9944 | Val Loss: 0.8047 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 27/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5020 | Train Acc: 0.9901 | Val Loss: 0.7924 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 28/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4979 | Train Acc: 0.9944 | Val Loss: 0.7225 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 29/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4982 | Train Acc: 0.9958 | Val Loss: 0.7640 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 30/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5133 | Train Acc: 0.9901 | Val Loss: 0.8181 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 31/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5061 | Train Acc: 0.9929 | Val Loss: 0.7390 | Val Acc: 0.8927\n",
      "\n",
      "[Epoch 32/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5070 | Train Acc: 0.9915 | Val Loss: 0.8403 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 33/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5171 | Train Acc: 0.9915 | Val Loss: 0.7801 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 34/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 220\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion)\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m| Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 180\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m    177\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    178\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 180\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    181\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    182\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# EfficientNet (pip install efficientnet-pytorch)\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "# ==========================\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==========================\n",
    "# ✅ ASPP Block 정의 (Global Branch 포함)\n",
    "# ==========================\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        # dilation = 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        # dilation = 1\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        # dilation = 6\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        # dilation = 12\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        \n",
    "        # Global Average Pool + 채널 변환\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # ⭐ global_avg도 256채널로 맞춰주는 Conv\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        # 최종적으로 5가지(conv1, conv3_1, conv3_6, conv3_12, global_avg)를 concat → out_channels * 5\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        # (batch, in_channels, 7, 7)\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        # -> (batch, in_channels, 1, 1)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        # -> (batch, 256, 1, 1)\n",
    "        global_avg = nn.functional.interpolate(\n",
    "            global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True\n",
    "        )\n",
    "        # -> (batch, 256, 7, 7)\n",
    "\n",
    "        # concat (256 each → 5 * 256 = 1280)\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        out = self.conv1x1_out(out)  # (batch, 256, 7, 7)\n",
    "        return out\n",
    "\n",
    "# ==========================\n",
    "# ✅ EfficientNet + VGG + ASPP 모델 정의\n",
    "# ==========================\n",
    "class EfficientNetVGGASPPHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EfficientNetVGGASPPHybrid, self).__init__()\n",
    "\n",
    "        # ✅ EfficientNet-b0\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        # ✅ VGG16\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # ✅ Feature Map 크기\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG16 마지막 Conv Layer 출력\n",
    "\n",
    "        # ✅ 7x7로 맞춤\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        # ✅ 1x1 Conv로 채널 맞춤\n",
    "        # 1280 → 1024\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        # 512 → 1024\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        # ✅ 두 feature 합치면 2048 → ASPP\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        # ✅ Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ✅ EfficientNet features\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)     # (batch, 1280, 7, 7)\n",
    "        eff_features = self.eff_conv1x1(eff_features)           # (batch, 1024, 7, 7)\n",
    "\n",
    "        # ✅ VGG16 features\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)              # (batch, 512, 7, 7)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)           # (batch, 1024, 7, 7)\n",
    "\n",
    "        # ✅ Feature Concatenation\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  # (batch, 2048, 7, 7)\n",
    "\n",
    "        # ✅ ASPP\n",
    "        aspp_features = self.aspp(fused_features)               # (batch, 256, 7, 7)\n",
    "\n",
    "        # ✅ Flatten & Classifier\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)  # (batch, 256*7*7)\n",
    "        output = self.classifier(aspp_features)                       # (batch, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ✅ 데이터 로딩\n",
    "# ==========================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 사용자 환경에 맞춰 수정\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetVGGASPPHybrid(num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 학습 함수\n",
    "# ==========================\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ==========================\n",
    "# ✅ 평가 함수\n",
    "# ==========================\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ==========================\n",
    "# ✅ 학습 루프 (Best 모델 저장)\n",
    "# ==========================\n",
    "best_acc = 0.0\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "          f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Best model 저장\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/45 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 1280, 1, 1], expected input[16, 3072, 7, 7] to have 1280 channels, but got 3072 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 202\u001b[0m\n\u001b[0;32m    200\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m--> 202\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m>\u001b[39m best_acc:\n",
      "Cell \u001b[1;32mIn[15], line 168\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m    165\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    166\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    170\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\IIALAB\\anaconda3\\envs\\solar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[15], line 117\u001b[0m, in \u001b[0;36mEfficientNetVGGASPPHybrid.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    113\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([eff_features, vgg_features], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# -> (batch, 2048, 7, 7)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# ASPP\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m aspp_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maspp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused_features\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# -> (batch, 256, 7, 7)\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[0;32m    121\u001b[0m aspp_features \u001b[38;5;241m=\u001b[39m aspp_features\u001b[38;5;241m.\u001b[39mview(aspp_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\IIALAB\\anaconda3\\envs\\solar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[15], line 52\u001b[0m, in \u001b[0;36mASPP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m global_avg \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39minterpolate(global_avg, size\u001b[38;5;241m=\u001b[39mconv3_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], \n\u001b[0;32m     49\u001b[0m                                        mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     51\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([conv1, conv3_1, conv3_6, conv3_12, global_avg], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1x1_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\IIALAB\\anaconda3\\envs\\solar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\IIALAB\\anaconda3\\envs\\solar\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\IIALAB\\anaconda3\\envs\\solar\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 1280, 1, 1], expected input[16, 3072, 7, 7] to have 1280 channels, but got 3072 channels instead"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm  # 학습 진행률 표시\n",
    "\n",
    "# ==========================\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "# ==========================\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        # dilation = 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        # dilation = 1\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        # dilation = 6\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        # dilation = 12\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        # Global Average Pool\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # 최종적으로 5가지(conv1, conv3_1, conv3_6, conv3_12, global_avg)를 concat → out_channels * 5\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv3_1 = self.conv3_1(x)\n",
    "        conv3_6 = self.conv3_6(x)\n",
    "        conv3_12 = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        # 원래 feature 크기에 맞춰 upsample\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv3_1.shape[2:], \n",
    "                                               mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1, conv3_1, conv3_6, conv3_12, global_avg], dim=1)\n",
    "        out = self.conv1x1_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EfficientNetVGGASPPHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EfficientNetVGGASPPHybrid, self).__init__()\n",
    "\n",
    "        # EfficientNet-b0\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        # 기존 FC 제거\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "        # VGG16 (PyTorch 1.12+)\n",
    "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        # 기존 FC 제거\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # Feature map 채널 수\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 보통 1280\n",
    "        vgg_out_features = 512  # VGG16 마지막 Conv 블록 출력 채널\n",
    "\n",
    "        # (h, w)를 7x7로 맞춤\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        # 각각 1x1 Conv로 변환\n",
    "        # 1280 → 1024\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        # 512 → 1024\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        # ASPP: in_channels=2048 (1024 + 1024)\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # EfficientNet features\n",
    "        eff_features = self.efficientnet.extract_features(x)   \n",
    "        # -> 보통 (batch, 1280, h, w)\n",
    "        eff_features = self.efficientnet_pool(eff_features)     \n",
    "        # -> (batch, 1280, 7, 7)\n",
    "        eff_features = self.eff_conv1x1(eff_features)          \n",
    "        # -> (batch, 1024, 7, 7)\n",
    "\n",
    "        # VGG16 features\n",
    "        vgg_features = self.vgg.features(x) \n",
    "        # -> (batch, 512, h', w')\n",
    "        vgg_features = self.vgg_pool(vgg_features) \n",
    "        # -> (batch, 512, 7, 7)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "        # -> (batch, 1024, 7, 7)\n",
    "\n",
    "        # Concat\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1) \n",
    "        # -> (batch, 2048, 7, 7)\n",
    "\n",
    "        # ASPP\n",
    "        aspp_features = self.aspp(fused_features)  \n",
    "        # -> (batch, 256, 7, 7)\n",
    "\n",
    "        # Flatten\n",
    "        aspp_features = aspp_features.view(aspp_features.size(0), -1)\n",
    "        # -> (batch, 256*7*7)\n",
    "\n",
    "        # Classifier\n",
    "        output = self.classifier(aspp_features)\n",
    "        # -> (batch, num_classes)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ✅ 데이터 로딩\n",
    "# ==========================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = 'C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel'\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetVGGASPPHybrid(num_classes=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ==========================\n",
    "# ✅ 학습 함수\n",
    "# ==========================\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ==========================\n",
    "# ✅ 평가 함수\n",
    "# ==========================\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ==========================\n",
    "# ✅ 학습 루프 (Best 모델 저장)\n",
    "# ==========================\n",
    "best_acc = 0.0\n",
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # 모델 저장\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"Best Accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
