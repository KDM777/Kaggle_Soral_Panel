{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3824 | Train Acc: 0.5480 | Val Loss: 2.3458 | Val Acc: 0.5254\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8542 | Train Acc: 0.8150 | Val Loss: 0.8132 | Val Acc: 0.8531\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6719 | Train Acc: 0.8983 | Val Loss: 0.9239 | Val Acc: 0.8023\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6610 | Train Acc: 0.9153 | Val Loss: 1.1160 | Val Acc: 0.7175\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6001 | Train Acc: 0.9421 | Val Loss: 0.7280 | Val Acc: 0.8870\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5524 | Train Acc: 0.9605 | Val Loss: 0.7456 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5722 | Train Acc: 0.9548 | Val Loss: 0.7690 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5978 | Train Acc: 0.9477 | Val Loss: 0.7629 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5714 | Train Acc: 0.9562 | Val Loss: 0.8689 | Val Acc: 0.8192\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5928 | Train Acc: 0.9506 | Val Loss: 0.7792 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6323 | Train Acc: 0.9364 | Val Loss: 0.7337 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5486 | Train Acc: 0.9703 | Val Loss: 0.7049 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5262 | Train Acc: 0.9746 | Val Loss: 0.7097 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5042 | Train Acc: 0.9816 | Val Loss: 0.6856 | Val Acc: 0.9040\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4984 | Train Acc: 0.9887 | Val Loss: 0.6758 | Val Acc: 0.9379\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5300 | Train Acc: 0.9788 | Val Loss: 0.7381 | Val Acc: 0.8983\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5568 | Train Acc: 0.9619 | Val Loss: 0.8909 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5141 | Train Acc: 0.9845 | Val Loss: 0.7732 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5013 | Train Acc: 0.9887 | Val Loss: 0.7262 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5033 | Train Acc: 0.9929 | Val Loss: 0.8031 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5348 | Train Acc: 0.9718 | Val Loss: 0.8219 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5211 | Train Acc: 0.9788 | Val Loss: 0.8292 | Val Acc: 0.8418\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5081 | Train Acc: 0.9859 | Val Loss: 0.7622 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5196 | Train Acc: 0.9816 | Val Loss: 0.8022 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4883 | Train Acc: 0.9915 | Val Loss: 0.7800 | Val Acc: 0.8531\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG19 + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "        # ✅ VGG19 사용\n",
    "        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # Freeze EfficientNet의 초기 블록: Freeze blocks 0~2, Unfreeze 나머지\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name or \"blocks.2\" in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # VGG 일부 Freeze (초반부)\n",
    "        for name, param in self.vgg.named_parameters():\n",
    "            if \"features.0\" in name or \"features.1\" in name or \"features.2\" in name or \"features.3\" in name or \"features.4\" in name or \"features.5\" in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG19 출력 채널\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  # (batch, 2048, 7, 7)\n",
    "        fused_features = self.res_block(fused_features)\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3085 | Train Acc: 0.3192 | Val Loss: 2.2524 | Val Acc: 0.3672\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2324 | Train Acc: 0.6130 | Val Loss: 1.8508 | Val Acc: 0.5706\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9072 | Train Acc: 0.8051 | Val Loss: 1.2082 | Val Acc: 0.6780\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7671 | Train Acc: 0.8729 | Val Loss: 0.8311 | Val Acc: 0.8588\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6481 | Train Acc: 0.9322 | Val Loss: 0.8099 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5611 | Train Acc: 0.9732 | Val Loss: 0.7883 | Val Acc: 0.8757\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5853 | Train Acc: 0.9633 | Val Loss: 0.7683 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6472 | Train Acc: 0.9421 | Val Loss: 0.8458 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5643 | Train Acc: 0.9760 | Val Loss: 0.8353 | Val Acc: 0.8475\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5706 | Train Acc: 0.9689 | Val Loss: 0.9024 | Val Acc: 0.8249\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6021 | Train Acc: 0.9661 | Val Loss: 0.7656 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5235 | Train Acc: 0.9845 | Val Loss: 0.7594 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5236 | Train Acc: 0.9831 | Val Loss: 0.7713 | Val Acc: 0.8983\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4998 | Train Acc: 0.9887 | Val Loss: 0.7553 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5005 | Train Acc: 0.9944 | Val Loss: 0.7579 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4930 | Train Acc: 0.9915 | Val Loss: 0.7702 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5164 | Train Acc: 0.9901 | Val Loss: 0.8464 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4849 | Train Acc: 0.9972 | Val Loss: 0.7754 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4734 | Train Acc: 0.9958 | Val Loss: 0.7319 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4811 | Train Acc: 0.9873 | Val Loss: 0.7686 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4999 | Train Acc: 0.9859 | Val Loss: 0.7744 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5313 | Train Acc: 0.9816 | Val Loss: 0.7913 | Val Acc: 0.8644\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4919 | Train Acc: 0.9887 | Val Loss: 0.7725 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5100 | Train Acc: 0.9915 | Val Loss: 0.8104 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4933 | Train Acc: 0.9944 | Val Loss: 0.7420 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5094 | Train Acc: 0.9859 | Val Loss: 0.7635 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4748 | Train Acc: 0.9986 | Val Loss: 0.7261 | Val Acc: 0.9040\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4942 | Train Acc: 0.9929 | Val Loss: 0.6899 | Val Acc: 0.9322\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4733 | Train Acc: 0.9944 | Val Loss: 0.7109 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4941 | Train Acc: 0.9944 | Val Loss: 0.7951 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4775 | Train Acc: 0.9958 | Val Loss: 0.7390 | Val Acc: 0.8870\n",
      "\n",
      "[Epoch 32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4664 | Train Acc: 0.9986 | Val Loss: 0.7069 | Val Acc: 0.8983\n",
      "\n",
      "[Epoch 33/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4640 | Train Acc: 0.9958 | Val Loss: 0.7156 | Val Acc: 0.9040\n",
      "\n",
      "[Epoch 34/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4689 | Train Acc: 0.9929 | Val Loss: 0.7655 | Val Acc: 0.8701\n",
      "\n",
      "[Epoch 35/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4674 | Train Acc: 0.9958 | Val Loss: 0.7455 | Val Acc: 0.8814\n",
      "\n",
      "[Epoch 36/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4644 | Train Acc: 0.9972 | Val Loss: 0.7426 | Val Acc: 0.8757\n",
      "\n",
      "[Epoch 37/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4819 | Train Acc: 0.9901 | Val Loss: 0.8069 | Val Acc: 0.8588\n",
      "\n",
      "[Epoch 38/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4603 | Train Acc: 0.9986 | Val Loss: 0.7526 | Val Acc: 0.8644\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3, dilation=3)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=5, dilation=5)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG19 + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "\n",
    "       # ✅ EfficientNet 일부 Freeze 적용\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name or \"blocks.2\" in name or \"blocks.3\" in name or \"blocks.4\" in name or \"blocks.5\" in name:  # ✅ EfficientNet 첫 3개 블록 Freeze\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True  # ✅ 이후 블록들은 학습 가능\n",
    "\n",
    "        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # ✅ VGG 일부 Freeze 적용 (초반부만 Freeze)\n",
    "        for name, param in self.vgg.named_parameters():\n",
    "            if \"features.0\" in name or \"features.1\" in name or \"features.2\" in name or \"features.3\" in name or \"features.4\" in name or \"features.5\" in name:\n",
    "                param.requires_grad = False  # ✅ 초반부 레이어는 Freeze\n",
    "            else:\n",
    "                param.requires_grad = True   # ✅ 이후의 레이어는 학습 가능\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG19의 출력 채널 수\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)  \n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # GAP 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 256 차원에서 512 차원으로 축소\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  \n",
    "        fused_features = self.res_block(fused_features)  \n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "[Epoch 1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4730 | Train Acc: 0.4831 | Val Loss: 4.3615 | Val Acc: 0.3616\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2118 | Train Acc: 0.6328 | Val Loss: 1.2507 | Val Acc: 0.6102\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1439 | Train Acc: 0.6511 | Val Loss: 1.1629 | Val Acc: 0.7006\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9701 | Train Acc: 0.7472 | Val Loss: 1.0549 | Val Acc: 0.7288\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8962 | Train Acc: 0.7881 | Val Loss: 1.0659 | Val Acc: 0.6893\n",
      "\n",
      "[Epoch 6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8959 | Train Acc: 0.7952 | Val Loss: 0.9200 | Val Acc: 0.8023\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9097 | Train Acc: 0.7881 | Val Loss: 0.9182 | Val Acc: 0.7910\n",
      "\n",
      "[Epoch 8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8282 | Train Acc: 0.8362 | Val Loss: 1.0892 | Val Acc: 0.7458\n",
      "\n",
      "[Epoch 9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7429 | Train Acc: 0.8701 | Val Loss: 1.0860 | Val Acc: 0.6836\n",
      "\n",
      "[Epoch 10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8034 | Train Acc: 0.8475 | Val Loss: 1.6789 | Val Acc: 0.4915\n",
      "\n",
      "[Epoch 11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9938 | Train Acc: 0.7288 | Val Loss: 1.1976 | Val Acc: 0.6723\n",
      "\n",
      "[Epoch 12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7869 | Train Acc: 0.8517 | Val Loss: 0.9876 | Val Acc: 0.7797\n",
      "\n",
      "[Epoch 13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6584 | Train Acc: 0.9153 | Val Loss: 0.7312 | Val Acc: 0.8814\n",
      "  [*] Best model saved.\n",
      "\n",
      "[Epoch 14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6131 | Train Acc: 0.9421 | Val Loss: 0.7853 | Val Acc: 0.8531\n",
      "\n",
      "[Epoch 15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6227 | Train Acc: 0.9308 | Val Loss: 0.9169 | Val Acc: 0.7684\n",
      "\n",
      "[Epoch 16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5746 | Train Acc: 0.9534 | Val Loss: 0.8726 | Val Acc: 0.7910\n",
      "\n",
      "[Epoch 17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5866 | Train Acc: 0.9506 | Val Loss: 0.8279 | Val Acc: 0.8305\n",
      "\n",
      "[Epoch 18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5238 | Train Acc: 0.9816 | Val Loss: 0.8956 | Val Acc: 0.7853\n",
      "\n",
      "[Epoch 19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4966 | Train Acc: 0.9915 | Val Loss: 0.8747 | Val Acc: 0.8136\n",
      "\n",
      "[Epoch 20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5541 | Train Acc: 0.9647 | Val Loss: 0.8382 | Val Acc: 0.8362\n",
      "\n",
      "[Epoch 21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5571 | Train Acc: 0.9633 | Val Loss: 0.8954 | Val Acc: 0.8023\n",
      "\n",
      "[Epoch 22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5589 | Train Acc: 0.9689 | Val Loss: 0.9004 | Val Acc: 0.8023\n",
      "\n",
      "[Epoch 23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5155 | Train Acc: 0.9802 | Val Loss: 0.8348 | Val Acc: 0.8418\n",
      "Early Stopping Triggered!\n",
      "\n",
      "Best Accuracy: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ SEED 설정 (재현성 확보)\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ✅ EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# ✅ Residual Block 정의\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return nn.ReLU()(x)\n",
    "\n",
    "# ✅ ASPP Block 정의\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1_for_global = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1x1_out = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv3_1_out = self.conv3_1(x)\n",
    "        conv3_6_out = self.conv3_6(x)\n",
    "        conv3_12_out = self.conv3_12(x)\n",
    "\n",
    "        global_avg = self.global_avg_pool(x)\n",
    "        global_avg = self.conv1_for_global(global_avg)\n",
    "        global_avg = nn.functional.interpolate(global_avg, size=conv1_out.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        out = torch.cat([conv1_out, conv3_1_out, conv3_6_out, conv3_12_out, global_avg], dim=1)\n",
    "        return self.conv1x1_out(out)\n",
    "\n",
    "# ✅ Hybrid Model (EfficientNet + VGG19 + Residual + ASPP)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Identity()\n",
    "        # ✅ VGG19 사용\n",
    "        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg.classifier = nn.Identity()\n",
    "\n",
    "        # Freeze EfficientNet의 초기 블록: Freeze blocks 0~2, Unfreeze 나머지\n",
    "        for name, param in self.efficientnet.named_parameters():\n",
    "            if \"blocks.0\" in name or \"blocks.1\" in name or \"blocks.2\" in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # VGG 일부 Freeze (초반부)\n",
    "        for name, param in self.vgg.named_parameters():\n",
    "            if \"features.0\" in name or \"features.1\" in name or \"features.2\" in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        efficientnet_out_features = self.efficientnet._conv_head.out_channels  # 1280\n",
    "        vgg_out_features = 512  # VGG19 출력 채널\n",
    "\n",
    "        self.efficientnet_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.vgg_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.eff_conv1x1 = nn.Conv2d(efficientnet_out_features, 1024, kernel_size=1)\n",
    "        self.vgg_conv1x1 = nn.Conv2d(vgg_out_features, 1024, kernel_size=1)\n",
    "\n",
    "        self.res_block = ResidualBlock(2048, 2048)\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.efficientnet.extract_features(x)\n",
    "        eff_features = self.efficientnet_pool(eff_features)\n",
    "        eff_features = self.eff_conv1x1(eff_features)\n",
    "\n",
    "        vgg_features = self.vgg.features(x)\n",
    "        vgg_features = self.vgg_pool(vgg_features)\n",
    "        vgg_features = self.vgg_conv1x1(vgg_features)\n",
    "\n",
    "        fused_features = torch.cat([eff_features, vgg_features], dim=1)  # (batch, 2048, 7, 7)\n",
    "        fused_features = self.res_block(fused_features)\n",
    "        aspp_features = self.aspp(fused_features)\n",
    "        gap_features = self.global_avg_pool(aspp_features)\n",
    "        flattened_features = gap_features.view(gap_features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# ✅ 데이터 로딩\n",
    "# ==============================\n",
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = \"C:/Users/IIALAB/Desktop/kdm/solar/kaggle/input/solar-panel-images/Faulty_solar_panel\"\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# ✅ 모델, 손실 함수, 최적화기 설정\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridModel(num_classes=6).to(device)  # 모델을 먼저 생성해야 함!\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Early Stopping 적용\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_acc = 0.0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs}]\")\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"  [*] Best model saved.\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping Triggered!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
